---
title: "FML_Assignment3"
author: "Chakri"
date: "2023-10-13"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


The file accidentsFull.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on initial reports and associated data in the system (some of which rely on GPS-assisted reporting).

Our goal here is to predict whether an accident just reported will involve an injury (MAX_SEV_IR = 1 or 2) or will not (MAX_SEV_IR = 0). For this purpose, create a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no.”

1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?

A-   no      yes 
   20721    21462 

2.Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 24 records. Use all three variables in the pivot table as rows/columns.

a.Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.

A- Probabilities of an Injury(INJURY=Yes) for six possible combinations of predictors(i.e, P1,P2,P3,P4,P5,P6)
   [1] 0.6666667 0.0000000 0.0000000 0.1818182 0.0000000 1.0000000


b.Classify the 24 accidents using these probabilities and a cutoff of 0.5.

A-  no    yes 
    14    10 
    
    out of 24 accidents data the cutoff probabilities of "no" are 14 and 10 are "yes"

c.Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.

A- 0, because from the pivot table of 'df1' we can say that the probability of INJURY where WEATHER_R=1 and TRAF_CON_R=1 is 0.

d.Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?

A- the classifications and rankings are not equivalent because due to cutoff probability difference please check below for it.

3.Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 

a.Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

A-                  Reference
   Prediction       no     yes
               no  1356   1068
               yes 6904   7546
               
-the above is the confusion matrix that was run by naiveBayes classifier and predict with validation data with INJURY as the response

b.What is the overall error of the validation set?

A- [1] 0.4724428(i.e, 47.2%) is the overall error of false positive and false negative over by summ of all the chances.


#loading the required libraries "e1071", "caret"
```{r}
library(e1071)
library(caret)
```

#reading the given file and calling first 24 rows
```{r}
accident_data <- read.csv("H:\\Kent Sem-1\\FML\\FML_class\\Assignments\\Assignment2\\accidentsFull.csv")
head(accident_data,n=24)
```

#dimension of the given data which is rows and columns
```{r}
dim(accident_data)

```

#creating a dummy variable called INJURy
```{r}
accident_data$INJURY <- ifelse(accident_data$MAX_SEV_IR>0, "yes", "no")
table(accident_data$INJURY)
```

#converting 
```{r}
accidents24 <- accident_data[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]
head(accidents24)

```

#creating a pivot table
```{r}
df1 <- ftable(accidents24)
df2 <- ftable(accidents24[,-1])
#print the tables
df1
df2

```

2.Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 24 records. Use all three variables in the pivot table as rows/columns.

a.Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.


```{r}
#if INJURY  is yes

P1= df1[3,1]/df2[1,1] #if TRAF_CON_R=0, WEATHER_R=1
P2= df1[3,2]/df2[1,2] #if TRAF_CON_R=1, WEATHER_R=1
P3= df1[3,3]/df2[1,3] #if TRAF_CON_R=2, WEATHER_R=1
P4= df1[4,1]/df2[2,1] #if TRAF_CON_R=0, WEATHER_R=2
P5= df1[4,2]/df2[2,2] #if TRAF_CON_R=1, WEATHER_R=2
P6= df1[4,3]/df2[2,3] #if TRAF_CON_R=2, WEATHER_R=2

#if INJURY  is no

Q1= df1[1,1]/df2[1.1] #if TRAD_CON_R=0, WEATHER_R=1
Q2= df1[1,2]/df2[1,2] #if TRAF_CON_R=1, WEATHER_R=1
Q3= df1[1,3]/df2[1,3] #if TRAF_CON_R=2, WEATHER_R=1
Q4= df1[2,1]/df2[2,1] #if TRAF_CON_R=0, WEATHER_R=2
Q5= df1[2,2]/df2[2,2] #if TRAF_CON_R=1, WEATHER_R=2
Q6= df1[2,3]/df2[2,3] #if TRAF_CON_R=2, WEATHER_R=2

print(c(P1,P2,P3,P4,P5,P6))
print(c(Q1,Q2,Q3,Q4,Q5,Q6))

```

2.

b.Let us compute 
  Classify the 24 accidents using these probabilities and a cutoff of 0.5.
```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
#for Injury=yes
  if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="0"){
    prob.inj[i]= P1
  }
  else if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="1"){
    prob.inj[i]=P2
    
  }
  else if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="2"){
    prob.inj[i]=P3
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="0"){
    prob.inj[i]=P4
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="1"){
    prob.inj[i]=P5
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="2"){
    prob.inj[i]=P6
  }

#for Injury=no
  else if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="0"){
    prob.inj[i]= Q1
  }
  else if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="1"){
    prob.inj[i]=Q2
  }
  else if(accidents24$WEATHER_R[i]=="1" && accidents24$TRAF_CON_R[i]=="2"){
    prob.inj[i]=Q3
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="0"){
    prob.inj[i]=Q4
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="1"){
    prob.inj[i]=Q5
  }
  else if(accidents24$WEATHER_R[i]=="2" && accidents24$TRAF_CON_R[i]=="2"){
    prob.inj[i]=Q6
  }
}

accidents24$prob.inj <- prob.inj
accidents24$predicted.prob <- ifelse(accidents24$prob.inj>0.5, "yes","no")
table(accidents24$predicted.prob)
```

2.
c.Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.
```{r}

P_W1_Iy = (df1[3,1]+df1[3,2]+df1[3,3])/(df1[3,1]+df1[3,2]+df1[3,3]+df1[4,1]+df1[4,2]+df1[4,3])
P_T1_Iy = (df1[3,2]+df1[4,2])/(df1[3,1]+df1[3,2]+df1[3,3]+df1[4,1]+df1[4,2]+df1[4,3])
PIy     = (df1[3,1]+df1[3,2]+df1[3,3]+df1[4,1]+df1[4,2]+df1[4,3])/24
P_W1_In = (df1[1,1]+df1[1,2]+df1[1,3])/(df1[1,1]+df1[1,2]+df1[1,3]+df1[2,1]+df1[2,2]+df1[2,3])
P_T1_In = (df1[1,2]+df1[2,2])/(df1[1,1]+df1[1,2]+df1[1,3]+df1[2,1]+df1[2,2]+df1[2,3])
PIn     = (df1[1,1]+df1[1,2]+df1[1,3]+df1[2,1]+df1[2,2]+df1[2,3])/24

P_Iy_W1.T1= (P_W1_Iy*P_T1_Iy*PIy)/((P_W1_Iy*P_T1_Iy*PIy)+(P_W1_In*P_T1_In*PIn))
P_Iy_W1.T1

```

2.
d.Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?


```{r}
nbc <- naiveBayes(INJURY ~ WEATHER_R+ TRAF_CON_R, data=accidents24)
nbt1 <- predict(nbc, newdata=accidents24, type="raw")
nbt1
accidents24$nbcpred.prob <- nbt1[,2]
accidents24$nbcpred.prob
accidents24

```

```{r}
#training the naiveBayes model by considering the predictors, Traffic and weather
nb1 <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, data = accidents24)

# Predicting the data using naiveBayes model
nbt1 <- predict(nb, newdata = accidents24, type = "raw")

# Inserting the newly predicted data to accidents24 dataframe
accidents24$nbpred.prob <- nbt1[,2] # Transfer the "Yes" nb prediction


# Consider cutoff value 0.5 for naiveBayes predictions
accidents24$nbpred.prob.condition <- ifelse(accidents24$nbpred.prob>0.5, "yes", "no") #if probability was greater than 0.4 the Injury will be yes
accidents24
```

```{r}
#Loading the klaR package for Naive Bayes
library(klaR) 

# Training the Naive Bayes model with Laplace
nb2 <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, data = accidents24, laplace = 1)

# predicting the data using the model
predict(nb2, newdata = accidents24[, c("INJURY", "WEATHER_R", "TRAF_CON_R")])

#predicting the data using the model with raw_probabilities
predict(nb2, newdata = accidents24[, c("INJURY", "WEATHER_R", "TRAF_CON_R")], type = "raw")
```

Comparing the naiveBayes model and exactBayes classification
```{r}
# Compare the naiveBayes model and exactBayes model
classification_match <- all(accidents24$nbpred.probability.condition == accidents24$pred.probability)
classification_match
probability_match <- all.equal(accidents24$nbpred.probability.condition, accidents24$pred.probability)
probability_match

# Checking if classifications and rankings are equivalent
if (classification_match && is.na(probability_match)) {
  cat("The classifications and rankings are equivalent.\n")
} else {
  cat("The classifications and rankings are not equivalent.\n")
}
```


#let us use caret
```{r}
nbc1 <- train(INJURY ~ TRAF_CON_R + WEATHER_R, 
      data = accidents24)

pred.nbc1 <- predict(nbc1, newdata = accidents24[,c("INJURY", "WEATHER_R", "TRAF_CON_R")])
pred1.nbc1 <- predict(nbc1, newdata = accidents24[,c("INJURY", "WEATHER_R", "TRAF_CON_R")],
                                    type = "raw")
pred.nbc1
pred1.nbc1

```


3.Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 

a.Run a naive Bayes classifier on the complete training set with the relevant predictors (and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

```{r}
set.seed(96)
train_data <- sample(row.names(accident_data),0.6*dim(accident_data)[1])
valid_data <- setdiff(row.names(accident_data),train_data)

train.df <- accident_data[train_data,]
valid.df <- accident_data[valid_data,]


```



```{r}



nb_c <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, data = train.df)
nb_p <- predict(nb_c, newdata= valid.df)
nb_p <- predict(nb_c, newdata= valid.df)

nb_p


valid.df$INJURY <- as.factor(valid.df$INJURY)

con_mat <- confusionMatrix(nb_p,valid.df$INJURY)
con_mat




```
3.
b.What is the overall error of the validation set?

```{r}
Overall_error <- (con_mat$table[1,2]+con_mat$table[2,1])/sum(con_mat$table)
Overall_error

```




